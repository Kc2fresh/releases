package edu.arizona.sista.qa.ranking.cache


import scala.collection.JavaConverters._
import java.util.concurrent.atomic.AtomicInteger
import edu.arizona.sista.qa.ranking.ProcessedQuestionSegments
import edu.arizona.sista.qa.retrieval.AnswerCandidate
import edu.arizona.sista.struct.Counter

/**
 * Save the features generated by models for QA pairs to a file
 * User: dfried
 * Date: 7/31/14
 */
trait FeatureCache {

  // map question answer representations to the features for those questions and answers
  def cache: FeatureCache.Cache

  def writeCache: Unit

  val cacheMisses = new AtomicInteger(0)
  val cacheHits = new AtomicInteger(0)

  def getFeatures(question: ProcessedQuestionSegments,
                  answer: AnswerCandidate,
                  featureNames: Set[String],
                  featureFn: => (Counter[String], String), readOnlyCache: Boolean = true, writeFrequency: Option[Int] = Some(100)): (Counter[String], String) = {
    val key = FeatureCache.mkKey(question, answer)
    // get cached features for this QA pair (will insert a new blank counter in the cache if not found)
    var (features, kernel) =  if (cache.contains(key))
      cache(key)
    else
      (new Counter[String], null)
    // see if we're missing any features
    if (! featureNames.forall(features.contains)) {
      // if so, then call the feature creation function and update the current values in the cache
      val numMisses = cacheMisses.incrementAndGet
      val (newFeats, newKernel): (Counter[String], String) = featureFn
      kernel = newKernel
      for (featureName <- featureNames) {
        features.setCount(featureName, newFeats.getCount(featureName))
      }
      cache(key) = (features, kernel)
      writeFrequency.foreach( wf => {
        if (!readOnlyCache && numMisses % wf == 0) this.synchronized {
          println("writing cache")
          writeCache
          println("write complete")
          System.gc
        }
      })
    } else {
      cacheHits.incrementAndGet
    }
    // only return those features asked for
    (features.filter(p => featureNames.contains(p._1)), kernel)
  }
}

object FeatureCache {
  type QAKey = (String, String) // question, answer
  type QAValue = (Counter[String], String) // features, kernel
  type Cache = collection.mutable.Map[QAKey, QAValue]

  private def getQuestionText(question: ProcessedQuestionSegments): String = (for {
    segment <- question.segments
    sentence <- segment.doc.sentences
    word <- sentence.words
  } yield word) mkString " "

  def mkKey(question: ProcessedQuestionSegments, answer: AnswerCandidate): QAKey = {
    (getQuestionText(question), answer.getText)
  }

  // thread-safe mutable map
  def mkCache: Cache = {
    new java.util.concurrent.ConcurrentHashMap[QAKey, QAValue]().asScala
  }

  def featuresToCounter(map: Map[String, Double]): Counter[String] = {
    val c = new Counter[String]
    for ((f, v) <- map) c.incrementCount(f, v)
    c
  }

  def counterToFeatures(counter: Counter[String]): Map[String, Double] = {
    counter.toSeq.toMap
  }
}

case class QAPair(question: String, answer: String, features: Map[String, Double], kernel: String)

object QAPair {
  def mkPair(question: ProcessedQuestionSegments, answer: AnswerCandidate, features: Counter[String], kernel: String) = {
    val (qText, aText) = FeatureCache.mkKey(question, answer)
    QAPair(qText, aText, features.toSeq.toMap, kernel)
  }
}
